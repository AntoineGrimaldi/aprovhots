{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8666b8-c02a-495b-898e-265b14e06b2b",
   "metadata": {},
   "source": [
    "# Perform online segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbf2679-8cc8-4b49-9aa7-f142a7a2dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2875bf50-1bf6-4930-b232-62024aba6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/aprovhots/dev\n"
     ]
    }
   ],
   "source": [
    "%cd ../dev/\n",
    "from dataset_creation_aprovis3d import aprovis3dDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0aae035-6bed-4cd0-9434-e1b9fff3152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import tonic, torch, os, pickle, copy, sys\n",
    "from tqdm import tqdm\n",
    "from hots.network import network\n",
    "from hots.layer import mlrlayer\n",
    "from hots.timesurface import timesurface\n",
    "from hots.utils import apply_jitter, get_loader, get_dataset_info, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig, online_accuracy, make_and_display_ts\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "#record_path = '/envau/work/neopto/USERS/GRIMALDI/HOTS/hotsline/Records/'\n",
    "record_path = '../Records/' #-> default if not mentionned\n",
    "\n",
    "data_path = '../../Data/RGB_frames2events/'\n",
    "# gives the data type - here we use experimental data, stored as npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd26065-5e5b-4326-af1b-a1473d488926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in the training set: 69\n",
      "number of samples in the testing set: 24\n"
     ]
    }
   ],
   "source": [
    "data_type = 'synthetic'\n",
    "# gives a patch_size to divide spatially the event streams\n",
    "patch_size = (672, 376)\n",
    "# gives a max duration for the samples of the dataset to divide temporally the event streams\n",
    "max_duration = 1e3 # (in ms)\n",
    "# labels given to the different classes of the dataset\n",
    "labelz = ['sea','gro']\n",
    "# original sensor_size of the DVS (width,height,polarity)\n",
    "sensor_size = [672, 376, 2]\n",
    "# discard samples with less than min_num_events events\n",
    "min_num_events = 1000\n",
    "# split the recordings into train and test sets with train_test_ratio ratio\n",
    "train_test_ratio = .75\n",
    "# gives the indexing of the event stream\n",
    "ordering = 'xytp'\n",
    "\n",
    "trainset = aprovis3dDataset(save_to=data_path, data_type=data_type, classes=labelz, train=True, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size)\n",
    "testset = aprovis3dDataset(save_to=data_path, data_type=data_type, classes=labelz, train=False, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size)\n",
    "trainloader = get_loader(trainset)\n",
    "testloader = get_loader(testset)\n",
    "\n",
    "num_sample_train = len(trainloader)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(trainset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2178205-a311-4b7a-91d0-4be04e49df40",
   "metadata": {},
   "source": [
    "# to make an animated time surface\n",
    "\n",
    "tau = 5e4\n",
    "ts_batch_size = 1000\n",
    "events, target = next(iter(trainloader))\n",
    "file_name = f'UCA_{target.item()}_{events.shape[1]}'\n",
    "make_and_display_ts(events.squeeze(0), file_name, trainset, tau, nb_frames = 100, ts_batch_size = ts_batch_size, polarity='on')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1de6eb-2962-4f4c-a5bf-cebb48e6b6f3",
   "metadata": {},
   "source": [
    "## Run the core HOTS network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e517b57-5530-4052-b617-7a6bb2e76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2023-01-03'\n",
    "dataset_name = 'aprovis_UCA_no_patch'\n",
    "ts_batch_size = int(5e4) \n",
    "\n",
    "tau_0 = 6e3\n",
    "tau_0 = 6e4\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [tau_0*2, tau_0*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo, record_path=record_path)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists(record_path):\n",
    "    os.mkdir(record_path)\n",
    "    os.mkdir(record_path+'networks/')\n",
    "    os.mkdir(record_path+'output/')\n",
    "    os.mkdir(record_path+'output/train/')\n",
    "    os.mkdir(record_path+'output/test/')\n",
    "    os.mkdir(record_path+'LR_results/')\n",
    "path = record_path+'networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(trainloader, trainset.ordering, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "917a9c9c-c8b3-414c-9654-e0c07223f639",
   "metadata": {},
   "source": [
    "hots.plotlayers();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a96e89-9ed3-4a44-9467-4cb667142082",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = None, training=True, ts_batch_size = ts_batch_size, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = None, training=False, ts_batch_size = ts_batch_size, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ccbb664-4efc-4621-90a6-d7110c7184fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "train_path = record_path+f'output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = record_path+f'output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "#trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "#testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b33932c-a669-4118-85e1-a498e20f424d",
   "metadata": {},
   "source": [
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed3ec8-fe43-44c1-958e-06e5cbfff489",
   "metadata": {},
   "source": [
    "## Divide the event streams into 16x16 patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2641486d-b9aa-48ce-b57d-a9f3e35e5f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in the training set: 3682\n",
      "number of samples in the testing set: 18114\n"
     ]
    }
   ],
   "source": [
    "patch_size = (16, 16)\n",
    "max_duration = None\n",
    "min_num_events = 10\n",
    "kfold = 10\n",
    "\n",
    "#weird way of splitting dataset between trainsets and testsets but works -> to improve\n",
    "trainset_output = aprovis3dDataset(save_to=train_path, data_type=data_type, classes=labelz, train=True, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size, train_test_ratio=1, min_num_events=min_num_events)\n",
    "testset_output = aprovis3dDataset(save_to=test_path, data_type=data_type, classes=labelz, train=True, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size, train_test_ratio=1, min_num_events=min_num_events)\n",
    "trainloader_output = get_loader(trainset_output, kfold = kfold)\n",
    "testloader_output = get_loader(testset_output)\n",
    "print(f'number of samples in the training set: {len(trainloader_output)}')\n",
    "print(f'number of samples in the testing set: {len(testloader_output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e855a-389e-4c49-a87d-7f15e2be8eac",
   "metadata": {},
   "source": [
    "## Example with only one layer of Multinomial Logistic Regression (MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fea09-1d7e-4ef9-83ee-1e28acbe867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device -> cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███████                                                                                                                                                                                                                                   | 1/33 [01:16<40:42, 76.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 0: 0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████████▏                                                                                                                                                                                                                           | 2/33 [02:32<39:27, 76.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 1: 0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████████████▎                                                                                                                                                                                                                    | 3/33 [03:48<38:09, 76.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 2: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████████████████████▎                                                                                                                                                                                                             | 4/33 [05:05<36:52, 76.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 3: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████████████████▍                                                                                                                                                                                                      | 5/33 [06:21<35:35, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 4: 0.353\n"
     ]
    }
   ],
   "source": [
    "jitter = (None, None)\n",
    "num_workers = 0\n",
    "learning_rate = 0.005\n",
    "betas = (0.9, 0.999)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "N_polarities = 32\n",
    "ts_size = (trainset_output.sensor_size[0],trainset_output.sensor_size[1],N_polarities)\n",
    "tau_cla = 6e4*32\n",
    "mlr_layer_name = f'{timestr}_LR_patches_{tau_cla}_{ts_size}_{learning_rate}_{betas}_{num_epochs}_{kfold}_{jitter}.pkl'\n",
    "\n",
    "model_path = record_path+'networks/' + mlr_layer_name\n",
    "results_path = record_path+'LR_results/' + mlr_layer_name\n",
    "train_path = record_path+f'output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = record_path+f'output/train/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainloader_output, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1ce18-6f81-4bdb-b79b-9cc683819167",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_loader(trainset, kfold=2, kfold_ind=1)\n",
    "\n",
    "mlr_threshold = None\n",
    "ts_batch_size = None\n",
    "\n",
    "#results_path = results_path[:-4]+'trainset.pkl'\n",
    "\n",
    "onlinac = online_accuracy(classif_layer, tau_cla, testloader, results_path, ts_size, trainset.ordering, len(labelz), mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = None, original_accuracy_nohomeo = None, online_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9ec1e-ab8b-4264-8636-a4ec9be86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(onlinac[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd1b81-f61d-43ac-a3f2-6117ecfc3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_path[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57182d-d75a-4efa-8955-d532c19b08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
