{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8666b8-c02a-495b-898e-265b14e06b2b",
   "metadata": {},
   "source": [
    "# Perform online segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbf2679-8cc8-4b49-9aa7-f142a7a2dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2875bf50-1bf6-4930-b232-62024aba6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/aprovhots/dev\n"
     ]
    }
   ],
   "source": [
    "%cd ../dev/\n",
    "from dataset_creation_aprovis3d import aprovis3dDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0aae035-6bed-4cd0-9434-e1b9fff3152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import tonic, torch, os, pickle, copy, sys\n",
    "from tqdm import tqdm\n",
    "from hots.network import network\n",
    "from hots.layer import mlrlayer\n",
    "from hots.timesurface import timesurface\n",
    "from hots.utils import apply_jitter, get_loader, get_dataset_info, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig, online_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "#record_path = '/envau/work/neopto/USERS/GRIMALDI/HOTS/hotsline/Records/'\n",
    "record_path = '../Records/' #-> default if not mentionned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff42293-a377-4262-b1b8-998eb4fd0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_display_ts(events, file_name, trainset, tau, polarity= 'off', nb_frames = 100, ts_batch_size = None, device = 'cuda'):\n",
    "    \n",
    "    if os.path.exists(f'figures/{file_name}_{polarity}.gif'):\n",
    "        return Image(filename=f'figures/{file_name}_{polarity}.gif')\n",
    "\n",
    "    else:\n",
    "        print('Building .gif ...')\n",
    "        frame_interval = int(events.shape[0]/nb_frames)\n",
    "        indices_of_frames = np.arange(0,events.shape[0],frame_interval)\n",
    "        if ts_batch_size and len(events)>ts_batch_size:\n",
    "            nb_batch = len(events)//ts_batch_size+1\n",
    "            previous_timestamp = []\n",
    "            outputs = torch.Tensor([])\n",
    "            ind_outputs = torch.Tensor([])\n",
    "            for load_nb in tqdm(range(nb_batch)):\n",
    "                all_ts, ind_filtered_timesurface, previous_timestamp = timesurface(events, trainset.sensor_size, trainset.ordering, tau = tau, ts_batch_size = ts_batch_size, load_number = load_nb, previous_timestamp = previous_timestamp, device = device)\n",
    "                indices_batch = indices_of_frames[np.where((indices_of_frames>=load_nb*ts_batch_size)&(indices_of_frames<(load_nb+1)*ts_batch_size))[0]]\n",
    "                for event_indice in indices_batch-load_nb*ts_batch_size:\n",
    "                    plt.imshow(all_ts[event_indice][0,:,:].cpu());\n",
    "                    plt.axis('off');\n",
    "                    plt.savefig(f'figures/ts_off_{file_name}_{event_indice+load_nb*ts_batch_size}');\n",
    "                    plt.imshow(all_ts[event_indice][1,:,:].cpu());\n",
    "                    plt.axis('off');\n",
    "                    plt.savefig(f'figures/ts_on_{file_name}_{event_indice+load_nb*ts_batch_size}');\n",
    "                del all_ts\n",
    "                torch.cuda.empty_cache()\n",
    "        else:\n",
    "            all_ts, ind_filtered = timesurface(events, trainset.sensor_size, trainset.ordering, tau = tau, device = device)\n",
    "            for event_indice in indices_of_frames:\n",
    "                plt.imshow(all_ts[event_indice][0,:,:].cpu());\n",
    "                plt.axis('off');\n",
    "                plt.savefig(f'figures/ts_off_{file_name}_{event_indice}');\n",
    "                plt.imshow(all_ts[event_indice][1,:,:].cpu());\n",
    "                plt.axis('off');\n",
    "                plt.savefig(f'figures/ts_on_{file_name}_{event_indice}');\n",
    "\n",
    "        frames_off = np.stack([iio.imread(f\"figures/ts_off_{file_name}_{x}.png\") for x in indices_of_frames], axis=0)\n",
    "        frames_on = np.stack([iio.imread(f\"figures/ts_on_{file_name}_{x}.png\") for x in indices_of_frames], axis=0)\n",
    "        iio.imwrite(f'figures/{file_name}_off.gif', frames_off)\n",
    "        iio.imwrite(f'figures/{file_name}_on.gif', frames_on)\n",
    "\n",
    "        for x in indices_of_frames:\n",
    "            os.remove(f\"figures/ts_off_{file_name}_{x}.png\")\n",
    "            os.remove(f\"figures/ts_on_{file_name}_{x}.png\")\n",
    "            \n",
    "        return Image(filename=f'figures/{file_name}_{polarity}.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd26065-5e5b-4326-af1b-a1473d488926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in the training set: 69\n",
      "number of samples in the testing set: 24\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../Data/RGB_frames2events/'\n",
    "# gives the data type - here we use experimental data, stored as npy\n",
    "data_type = 'synthetic'\n",
    "# gives a patch_size to divide spatially the event streams\n",
    "patch_size = (672, 376)\n",
    "# gives a max duration for the samples of the dataset to divide temporally the event streams\n",
    "max_duration = 1e3 # (in ms)\n",
    "# labels given to the different classes of the dataset\n",
    "labelz = ['sea','gro']\n",
    "# original sensor_size of the DVS (width,height,polarity)\n",
    "sensor_size = [672, 376, 2]\n",
    "# discard samples with less than min_num_events events\n",
    "min_num_events = 1000\n",
    "# split the recordings into train and test sets with train_test_ratio ratio\n",
    "train_test_ratio = .75\n",
    "# gives the indexing of the event stream\n",
    "ordering = 'xytp'\n",
    "\n",
    "trainset = aprovis3dDataset(save_to=data_path, data_type=data_type, classes=labelz, train=True, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size)\n",
    "testset = aprovis3dDataset(save_to=data_path, data_type=data_type, classes=labelz, train=False, patch_size=patch_size, max_duration=max_duration, sensor_size=sensor_size)\n",
    "trainloader = get_loader(trainset)\n",
    "testloader = get_loader(testset)\n",
    "\n",
    "num_sample_train = len(trainloader)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(trainset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f3e57a-5b84-45b5-9585-b7fd5cf9b8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 41868, 4])\n"
     ]
    }
   ],
   "source": [
    "events, target = next(iter(trainloader))\n",
    "print(events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c628b1d-5b42-4c02-8750-888e8897f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building .gif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 22/42 [02:55<04:17, 12.88s/it]"
     ]
    }
   ],
   "source": [
    "tau = 5e4\n",
    "ts_batch_size = 1000\n",
    "file_name = f'UCA_{target.item()}_{events.shape[1]}'\n",
    "make_and_display_ts(events.squeeze(0), file_name, trainset, tau, nb_frames = 100, ts_batch_size = ts_batch_size, polarity='on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f248c7-0d47-4e03-bfbf-b98802a1ec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_and_display_ts(events.squeeze(0), file_name, trainset, tau, nb_frames = 100, ts_batch_size = ts_batch_size, polarity='off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1de6eb-2962-4f4c-a5bf-cebb48e6b6f3",
   "metadata": {},
   "source": [
    "## Run the core HOTS network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e517b57-5530-4052-b617-7a6bb2e76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2023-01-03'\n",
    "dataset_name = 'aprovis_UCA_no_patch'\n",
    "ts_batch_size = int(5e4) \n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [6e4*2, 6e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo, record_path=record_path)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists(record_path):\n",
    "    os.mkdir(record_path)\n",
    "    os.mkdir(record_path+'networks/')\n",
    "    os.mkdir(record_path+'output/')\n",
    "    os.mkdir(record_path+'output/train/')\n",
    "    os.mkdir(record_path+'output/test/')\n",
    "    os.mkdir(record_path+'LR_results/')\n",
    "path = record_path+'networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(trainloader, trainset.ordering, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5cab4-fe4a-4371-9116-bd28cfe67ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.plotlayers();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a96e89-9ed3-4a44-9467-4cb667142082",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = None, training=True, ts_batch_size = ts_batch_size, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = None, training=False, ts_batch_size = ts_batch_size, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e855a-389e-4c49-a87d-7f15e2be8eac",
   "metadata": {},
   "source": [
    "## Example with only one layer of Multinomial Logistic Regression (MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fea09-1d7e-4ef9-83ee-1e28acbe867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "num_workers = 0\n",
    "learning_rate = 0.005\n",
    "betas = (0.9, 0.999)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "N_polarities = 32\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_polarities)\n",
    "tau_cla = 6e4*32\n",
    "mlr_layer_name = f'{timestr}_LR_{tau_cla}_{ts_size}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "\n",
    "model_path = record_path+'networks/' + mlr_layer_name\n",
    "results_path = record_path+'LR_results/' + mlr_layer_name\n",
    "train_path = record_path+f'output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "train_path = record_path+f'output/train/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1ce18-6f81-4bdb-b79b-9cc683819167",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_loader(trainset, kfold=2, kfold_ind=1)\n",
    "\n",
    "mlr_threshold = None\n",
    "ts_batch_size = None\n",
    "\n",
    "#results_path = results_path[:-4]+'trainset.pkl'\n",
    "\n",
    "onlinac = online_accuracy(classif_layer, tau_cla, testloader, results_path, ts_size, trainset.ordering, len(labelz), mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = None, original_accuracy_nohomeo = None, online_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9ec1e-ab8b-4264-8636-a4ec9be86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(onlinac[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd1b81-f61d-43ac-a3f2-6117ecfc3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_path[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57182d-d75a-4efa-8955-d532c19b08e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
