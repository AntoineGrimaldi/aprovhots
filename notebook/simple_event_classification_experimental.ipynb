{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4045e17a-be9f-4b5a-905d-ded1c128fcb3",
   "metadata": {},
   "source": [
    "# Open experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38dd7c0-2093-4b79-a740-3b651f0f50ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of all files : \n",
      " ['DVS128-2021-08-07T09-54-36+0300-Bern13XX-0.aedat4', 'DVS128-2021-08-07T09-09-27+0300-Bern13XX-0.aedat4', 'DVS128-2021-08-07T10-00-09+0300-Bern13XX-0.aedat4', 'DVS128-2021-08-07T09-28-28+0300-Bern13XX-0.aedat4', 'DVS128-2021-08-07T10-16-37+0300-Bern13XX-0.aedat4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import aedat\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = '/home/INT/grimaldi.a/Documents/projets/WP3/07_08_2021_field_data_collection'\n",
    "list = os.listdir(path)\n",
    "print(f'list of all files : \\n {list}')\n",
    "\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/model/')\n",
    "    os.mkdir('../Records/train/')\n",
    "    os.mkdir('../Records/test/')\n",
    "if not os.path.exists('../Data/'):\n",
    "    os.mkdir('../Data/')\n",
    "\n",
    "labelz = [0] # to change!\n",
    "t_index_file, x_index_file, y_index_file, p_index_file = 0, 1, 2, 3\n",
    "x_index, y_index, t_index, p_index = 0, 1, 2, 3\n",
    "\n",
    "patch_R = 16\n",
    "duration = None\n",
    "min_events = 20\n",
    "#duration = int(1e7)\n",
    "\n",
    "\n",
    "#you can load the data and make patches on the pixel grid to divide the DVS \n",
    "#recordings and obtain more samples\n",
    "def load_data_patches(path, rec_number, patch_size, time_limit, min_events):\n",
    "    f_name = f'../Data/aprovisexp_{patch_size}_{rec_number}_{time_limit}_{min_events}.pkl'\n",
    "    if os.path.isfile(f_name):\n",
    "        with open(f_name, 'rb') as file:\n",
    "            events_stacked, label_stacked, indices = pickle.load(file)\n",
    "    else:\n",
    "        events_stacked = np.array([])\n",
    "        label_stacked = []\n",
    "        indices = [0]\n",
    "        for num in rec_number:\n",
    "            fname_aedat = f'{path}/{list[num]}'\n",
    "            decoder = aedat.Decoder(fname_aedat)\n",
    "            events_list = np.array([])\n",
    "            # this use of the decoder is not optimal at all, to be improved\n",
    "            for packet in decoder:\n",
    "                for i in range(len(packet['events'])):\n",
    "                    events_list = np.vstack([events_list, np.array([packet['events'][i][x_index_file], packet['events'][i][y_index_file], packet['events'][i][t_index_file], packet['events'][i][p_index_file]])]) if events_list.size else np.array([packet['events'][i][x_index_file], packet['events'][i][y_index_file], packet['events'][i][t_index_file], packet['events'][i][p_index_file]])\n",
    "            initial_time = events_list[0,t_index]\n",
    "            events_list[:,t_index] -= initial_time\n",
    "            label = labelz[0]\n",
    "            print(f'file name: {list[num]} \\n total number of events: {len(events_list)} \\n recording time: {events_list[-1,t_index]*1e-6} sec \\n \\n')\n",
    "            width, height = 128, 128\n",
    "            pbar = tqdm(total=width//patch_size*height//patch_size)\n",
    "            for x in range(width//patch_size):\n",
    "                for y in range(height//patch_size):\n",
    "                    events_patch = events_list[\n",
    "                                   (events_list[:,x_index]>=x*patch_size)&(events_list[:,x_index]<(x+1)*patch_size)&\n",
    "                                   (events_list[:,y_index]>=y*patch_size)&(events_list[:,y_index]<(y+1)*patch_size)]\n",
    "                    events_patch[:,x_index] -= x*patch_size\n",
    "                    events_patch[:,y_index] -= y*patch_size\n",
    "    #                if time_limit:\n",
    "    #                    time = 0\n",
    "    #                    events_patch[:,t_index] = events_patch[(events_patch[:,t_index]<time)]\n",
    "                    if len(events_patch)<min_events:\n",
    "                        pass\n",
    "                    else:\n",
    "                        events_patch[:,t_index] -= np.min(events_patch[:,t_index])\n",
    "                        indices.append(indices[-1]+events_patch.shape[0])\n",
    "                        label_stacked.append(label)\n",
    "                        events_stacked = np.vstack([events_stacked, events_patch]) if events_stacked.size else events_patch\n",
    "                    pbar.update(1)\n",
    "            # print(np.max(events_patch[:,x_index]), np.max(events_patch[:,y_index]), np.max(events_patch[:,t_index]))\n",
    "            pbar.close()\n",
    "            decoder = None\n",
    "        with open(f_name, 'wb') as file:\n",
    "            pickle.dump([events_stacked, label_stacked, indices], file, pickle.HIGHEST_PROTOCOL)\n",
    "    return events_stacked, label_stacked, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18814d91-7e85-437d-bd58-d3298acec2f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_patches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1308605/2142720967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load and save the data (select specific recordings for the training or testing set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevents_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data_patches' is not defined"
     ]
    }
   ],
   "source": [
    "#load and save the data (select specific recordings for the training or testing set\n",
    "#here only one recording to train because the views are not labeled)\n",
    "events_train, label_train, indices_train = load_data_patches(path, [0], patch_R, duration, min_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff5325-7fc0-4e48-b33b-97dd6bffea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'averaged number of events per sample: {np.round(events_train.shape[0]/len(indices_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576b46df-cf69-48aa-a3ab-988a9bf04ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_test, label_test, indices_test = load_data_patches(path, [0,2], patch_R, duration, min_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042ba58-c99f-4b86-b888-f9c4df2cd469",
   "metadata": {},
   "source": [
    "There are way more events for ground compare to sea data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb35a28-3c32-43eb-a002-f826b61bd5d7",
   "metadata": {},
   "source": [
    "# Train the MLR model on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d4d281-b0f8-4f74-a120-12195801e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from HOTS.Tools import LRtorch, classification_numbevents\n",
    "\n",
    "num_workers = 0 # ajouter num_workers si besoin!\n",
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "sample_space = 1\n",
    "tau_cla = 1e6\n",
    "jitonic = [None, None]\n",
    "subset_size = None\n",
    "verbose=True\n",
    "dataset = 'aprovisynt'\n",
    "nb_pola = 2\n",
    "N = patch_R*patch_R*nb_pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1018f0-a7f7-4bbd-8d2f-98945922d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_MLR(events_train, label_train, indices_train, tau_cla, patch_R):\n",
    "    num_workers = 0 # ajouter num_workers si besoin!\n",
    "    learning_rate = 0.005\n",
    "    beta1, beta2 = 0.9, 0.999\n",
    "    betas = (beta1, beta2)\n",
    "    num_epochs = 2 ** 5 + 1\n",
    "    sample_space = 1\n",
    "    jitonic = [None, None]\n",
    "    subset_size = None\n",
    "    verbose=True\n",
    "    dataset = 'aprovisynt'\n",
    "    nb_pola = 2\n",
    "    N = patch_R*patch_R*nb_pola\n",
    "    \n",
    "    nb_digit = len(indices_train)\n",
    "\n",
    "    transform = tonic.transforms.Compose([tonic.transforms.ToTimesurface(surface_dimensions=False, tau=tau_cla, decay=\"exp\", merge_polarities=False)])\n",
    "    train_dataset = AERDataset(tensors=(events_train, label_train), indices=indices_train, name = 'aprovisynt', transform=transform)\n",
    "    loader = DataLoader(train_dataset, shuffle=True)\n",
    "\n",
    "    torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "    criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    amsgrad = True #or False gives similar results\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if verbose:\n",
    "        print(f'device -> {device} - num workers -> {num_workers}')\n",
    "\n",
    "    n_classes = len(train_dataset.classes)\n",
    "    logistic_model = LRtorch(N, n_classes)\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=betas, amsgrad=amsgrad\n",
    "    )\n",
    "    pbar = tqdm(total=int(num_epochs))\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        losses = []\n",
    "        for X, label in loader:\n",
    "            X, label = X[0].to(device) ,label[0].to(device)\n",
    "            X = X.reshape(X.shape[0], N)\n",
    "            outputs = logistic_model(X)\n",
    "\n",
    "            n_events = X.shape[0]\n",
    "            labels = label*torch.ones(n_events).type(torch.LongTensor).to(device)\n",
    "            labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).type(torch.DoubleTensor).to(device)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f'loss for epoch number {epoch}: {loss}')\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    with open(f'../Records/model/torch_model_{tau_cla}_{patch_R}.pkl', 'wb') as file:\n",
    "        pickle.dump([logistic_model, losses], file, pickle.HIGHEST_PROTOCOL)\n",
    "    return logistic_model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616c34a-7e7e-45e9-a5d1-e9bd07dab7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device -> cuda - num workers -> 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▎                                                                                                                                         | 1/33 [05:48<3:05:47, 348.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 0: 0.5944622111529847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▌                                                                                                                                     | 2/33 [11:26<2:56:57, 342.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 1: 0.518935940178484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████████▉                                                                                                                                 | 3/33 [17:10<2:51:37, 343.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 2: 0.18026937411587488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████▏                                                                                                                            | 4/33 [22:48<2:44:48, 340.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 3: 0.09166800830549238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████████▌                                                                                                                        | 5/33 [28:32<2:39:37, 342.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 4: 0.2560523270769089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████████▊                                                                                                                    | 6/33 [34:18<2:34:28, 343.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 5: 0.5154303404250081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████████████                                                                                                                | 7/33 [40:03<2:29:05, 344.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 6: 0.5267742062830822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████████████▍                                                                                                           | 8/33 [45:49<2:23:33, 344.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 7: 0.48326569943036246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████████████▋                                                                                                       | 9/33 [51:34<2:17:56, 344.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 8: 0.44446902939139854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████████▋                                                                                                  | 10/33 [57:19<2:12:11, 344.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 9: 0.22967189387281625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████████████▎                                                                                            | 11/33 [1:03:05<2:06:34, 345.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 10: 0.07370376067358542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████████████████████▌                                                                                        | 12/33 [1:08:51<2:00:55, 345.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 11: 0.024918817003491616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████████████████████████▊                                                                                    | 13/33 [1:14:37<1:55:11, 345.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 12: 0.08807035410152327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████████████████████████████▉                                                                                | 14/33 [1:20:24<1:49:36, 346.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 13: 0.03588291748553633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████▏                                                                           | 15/33 [1:26:15<1:44:14, 347.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 14: 0.025751075656938058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████████████████████████████▍                                                                       | 16/33 [1:32:16<1:39:37, 351.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 15: 0.04820868039888258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████████████████████████▌                                                                   | 17/33 [1:38:00<1:33:08, 349.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 16: 0.24441162567871005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████████████████████████████▊                                                               | 18/33 [1:43:43<1:26:50, 347.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 17: 0.09717107712905806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████████████████████████████████████                                                           | 19/33 [1:49:25<1:20:41, 345.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 18: 0.052508626331754744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████████████████████▏                                                      | 20/33 [1:55:09<1:14:48, 345.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 19: 0.09827968865956782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 21/33 [2:00:53<1:08:58, 344.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 20: 0.07766202660277462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 22/33 [2:06:37<1:03:11, 344.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 21: 0.14439399620072688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 23/33 [2:12:23<57:29, 344.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 22: 0.029637334922204186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 24/33 [2:18:07<51:41, 344.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 23: 0.03592544701688897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 25/33 [2:23:44<45:37, 342.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 24: 0.23975008025733494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 26/33 [2:29:24<39:51, 341.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 25: 0.04170355389943178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 27/33 [2:35:01<34:01, 340.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 26: 0.06291298285565945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 28/33 [2:40:50<28:34, 342.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 27: 0.05095172132700628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 29/33 [2:46:31<22:49, 342.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 28: 0.16820862809894782\n"
     ]
    }
   ],
   "source": [
    "logistic_model, losses = fit_MLR(events_train, label_train, indices_train, tau_cla, patch_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78b8c8-d22d-4df1-8df1-b054cf523086",
   "metadata": {},
   "source": [
    "# Make testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33383d5a-fe86-47e4-80e0-2f90f762586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device -> cuda - num workers -> 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▉                                                                                                                                                               | 1/33 [06:16<3:20:40, 376.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 0: 0.17467905925766614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▉                                                                                                                                                          | 2/33 [12:36<3:15:39, 378.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 1: 0.17662391152887252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▉                                                                                                                                                     | 3/33 [18:55<3:09:23, 378.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 2: 0.11801718763535003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████▉                                                                                                                                                | 4/33 [25:13<3:02:53, 378.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 3: 0.16968010056796534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████████████▊                                                                                                                                           | 5/33 [31:30<2:56:20, 377.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 4: 0.14130065193430724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████████████▊                                                                                                                                      | 6/33 [37:45<2:49:37, 376.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 5: 0.30028180696686035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████████████████▊                                                                                                                                 | 7/33 [44:04<2:43:37, 377.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 6: 0.3575622630333244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████▊                                                                                                                            | 8/33 [50:22<2:37:22, 377.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch number 7: 0.2934739490393453\n"
     ]
    }
   ],
   "source": [
    "thres = None\n",
    "chance = .5\n",
    "\n",
    "for tau_cla in [10000, 100000, 1000000, 10000000, 100000000]:\n",
    "    \n",
    "    if os.path.isfile(f'../Records/model/torch_model_{tau_cla}_{patch_R}.pkl'):\n",
    "        with open(f'../Records/model/torch_model_{tau_cla}_{patch_R}.pkl', 'rb') as file:\n",
    "            logistic_model, losses = pickle.load(file)\n",
    "    else: \n",
    "        logistic_model, losses = fit_MLR(events_train, label_train, indices_train, tau_cla, patch_R)\n",
    "    \n",
    "    transform = tonic.transforms.Compose([tonic.transforms.ToTimesurface(surface_dimensions=False, tau=tau_cla, decay=\"exp\", merge_polarities=False)])\n",
    "    test_dataset = AERDataset(tensors=(events_test, label_test), indices=indices_test, name = 'aprovisynt', transform=transform)\n",
    "    loader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "    nb_test = len(loader)\n",
    "    nb_digit = len(indices_test)\n",
    "\n",
    "    torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "    criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    amsgrad = True #or False gives similar results\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if verbose:\n",
    "        print(f'device -> {device} - num workers -> {num_workers}')\n",
    "\n",
    "    n_classes = len(test_dataset.classes)\n",
    "    logistic_model = LRtorch(N, n_classes)\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=betas, amsgrad=amsgrad\n",
    "    )\n",
    "    pbar = tqdm(total=int(len(loader)))\n",
    "    likelihood, true_target = [], []\n",
    "    for X, label in loader:\n",
    "        X, label = X[0].to(device) ,label[0].to(device)\n",
    "        X = X.reshape(X.shape[0], N)\n",
    "        outputs = logistic_model(X)\n",
    "\n",
    "        n_events = X.shape[0]\n",
    "        labels = label*torch.ones(n_events).type(torch.LongTensor).to(device)\n",
    "        labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).type(torch.DoubleTensor).to(device)\n",
    "\n",
    "        likelihood.append(outputs.cpu().detach().numpy())\n",
    "        true_target.append(label.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    meanac, onlinac, lastac, maxprobac, maxevac, maxevac_end, truepos, falsepos, lastev = classification_numbevents(likelihood, true_target, thres, nb_test, chance, lenmat=int(1e6))\n",
    "    print(meanac, lastac, maxprobac, maxevac, maxevac_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ea0b44c-d447-442a-b34f-f94a43fa644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/INT/grimaldi.a/Documents/projets/HOTS/HOTS/HOTS/Tools.py:570: RuntimeWarning: Mean of empty slice\n",
      "  onlinac = np.nanmean(matscor, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples where not classified\n"
     ]
    }
   ],
   "source": [
    "from HOTS.Tools import classification_numbevents\n",
    "thres = None\n",
    "nb_test = len(loader)\n",
    "chance = .5\n",
    "meanac, onlinac, lastac, maxprobac, maxevac, maxevac_end, truepos, falsepos, lastev = classification_numbevents(likelihood, true_target, thres, nb_test, chance, lenmat=int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea669af2-36dc-47c9-ac4c-e4d386a39960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602808618457754 0.47058823529411764 0.6323529411764706 0.75 0.75\n"
     ]
    }
   ],
   "source": [
    "print(meanac, lastac, maxprobac, maxevac, maxevac_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6687707e-3a1e-4236-8dc6-f09e5f4147b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (556051,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4101/2364311687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monlinac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxprobac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxevac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxevac_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (556051,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(onlinac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975e267-0fb3-49fb-9158-a054c133f904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
